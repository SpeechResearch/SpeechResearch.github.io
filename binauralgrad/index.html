<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.66.0" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<link rel="stylesheet" href="../css/normalize.css">
<link rel="stylesheet" href="../css/skeleton.css">
<link rel="stylesheet" href="../css/custom.css">
<link rel="alternate" href="index.xml" type="application/rss+xml" title="Speech Research">
<link rel="shortcut icon" href="favicon.png" type="image/x-icon" />
<title>BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis - Speech Research</title>
</head>
<body>

<div class="container">

	<header role="banner">
		
			
		
		
	</header>


	<main role="main">
		<article itemscope itemtype="https://schema.org/BlogPosting">
            <h1 class="entry-title" itemprop="headline">BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis</h1>
			
			<section itemprop="entry-text">
				<br>
<!-- Paper: <a href="../papers/fastspeech_2019.pdf">FastSpeech: Fast, Robust and Controllable Text to Speech</a> -->
<p>ArXiv: Comming soon
<h2 id="authors">Authors</h2>
<ul>
<li>Yichong Leng* (University of Science and Technology of China) <a href="mailto:lyc123go@mail.ustc.edu.cn">lyc123go@mail.ustc.edu.cn</a></li>
<li>Zehua Chen* (Imperial College London) <a href="mailto:zehua.chen18@imperial.ac.uk">zehua.chen18@imperial.ac.uk</a></li>
<li>Junliang Guo (Microsoft Research) <a href="mailto:junliangguo@microsoft.com">junliangguo@microsoft.com</a></li>
<li>Haohe Liu (University of Surrey) <a href="mailto:hl01486@surrey.ac.uk">hl01486@surrey.ac.uk</a></li>
<li>Jiawei Chen (South China University of Technology) <a href="mailto:csjiaweichen@mail.scut.edu.cn">csjiaweichen@mail.scut.edu.cn</a></li>
<li>Xu Tan^ (Microsoft Research Asia) <a href="mailto:xuta@microsoft.com">xuta@microsoft.com</a></li>
<li>Danilo Mandic (Imperial College London) <a href="mailto:d.mandic8@imperial.ac.uk">d.mandic8@imperial.ac.uk</a></li>
<li>Lei He (Microsoft Azure Speech) <a href="mailto:helei@microsoft.com">helei@microsoft.com</a></li>
<li>Xiang-Yang Li (University of Science and Technology of China) <a href="mailto:xiangyangli@ustc.edu.cn">xiangyangli@ustc.edu.cn</a></li>
<li>Tao Qin (Microsoft Research Asia) <a href="mailto:taoqin@microsoft.com">taoqin@microsoft.com</a></li>
<li>Sheng Zhao (Microsoft Azure Speech) <a href="mailto:szhao@microsoft.com">szhao@microsoft.com</a></li>
<li>Tie-Yan Liu (Microsoft Research Asia) <a href="mailto:tyliu@microsoft.com">tyliu@microsoft.com</a></li>
</ul>
<p><small>* Equal contribution.</small></p>
<p><small>^ Corresponding author.</small></p>
<h2 id="abstract">Abstract</h2>
<p>  Binaural audio plays a significant role in constructing immersive augmented and virtual realities. As it is expensive to record binaural audio from the real world, synthesizing them from mono audio has attracted increasing attention. This synthesis process involves not only the basic physical warping of the mono audio, but also room reverberations and head/ear related filtrations, which, however, are difficult to accurately simulate in traditional digital signal processing. In this paper, we formulate the synthesis process from a different perspective by decomposing the binaural audio into a common part that shared by the left and right channels as well as a specific part that differs in each channel. Accordingly, we propose BinauralGrad, a novel two-stage framework equipped with diffusion models to synthesize them respectively. Specifically, in the first stage, the common information of the binaural audio is generated with a single-channel diffusion model conditioned on the mono audio, based on which the binaural audio is generated by a two-channel diffusion model in the second stage. Combining this novel perspective of two-stage synthesis with advanced generative models (i.e., the diffusion models),the proposed BinauralGrad is able to generate accurate and high-fidelity binaural audio samples.Experiment results show that on a benchmark dataset, BinauralGrad outperforms the existing baselines by a large margin in terms of both object and subject evaluation metrics (Wave L2: 0.128 vs. 0.157, MOS: 3.80 vs. 3.61).</p>
<h2 id="Demo_Video">Demo Video</h2>

<p> The below video is used to show the comparison of our BinauralGrad with recording, WarpNet baseline, WaveNet baseline, Digital Signal Processing (DSP) baseline, which can be downloaded in <a href="https://msramllasc.blob.core.windows.net/modelrelease/binauralgrad/Demo.mp4">here</a> if there is problem in online watching.</p>

<video id="video" controls="" preload="none" poster="none">
      <source id="mp4" src="../audio/binauralgrad/Demo.mp4" type="video/mp4">
</video>


<p> Note the we show the binaural audio from recording, BinauralGrad and baseline systems in one demo video with montage. If you are interested in the corresponding video with a system sololy, 
  you can download it in <a href="https://msramllasc.blob.core.windows.net/modelrelease/binauralgrad/Recording_demo.mp4">Recording</a>, 
  <a href="https://msramllasc.blob.core.windows.net/modelrelease/binauralgrad/BinauralGrad_demo.mp4">BinauralGrad</a>, 
  <a href="https://msramllasc.blob.core.windows.net/modelrelease/binauralgrad/WarpNet_demo.mp4">WarpNet</a>, 
  <a href="https://msramllasc.blob.core.windows.net/modelrelease/binauralgrad/Wavenet_demo.mp4">WaveNet</a>,
   <a href="https://msramllasc.blob.core.windows.net/modelrelease/binauralgrad/DSP_demo.mp4">DSP</a>.</p>

<h2 id="audio-samples">Audio Samples</h2>
<p> The following part is 5 audio samples, each of which consists of 5 audio from recording, BinauralGrad (Our method), WarpNet baseline, WaveNet baseline, Digital Signal Processing (DSP) baseline.</p>
<p><em>Sample 1.</em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Recording</th>
<th style="text-align: center">BinauralGrad</th>
<th style="text-align: center">WarpNet</th>
<th style="text-align: center">WaveNet</th>
<th style="text-align: center">DSP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/recording_1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/ddpm_1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/warpnet_1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/wavenet_1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/dsp_1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<p><em>Sample 2.</em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Recording</th>
<th style="text-align: center">BinauralGrad</th>
<th style="text-align: center">WarpNet</th>
<th style="text-align: center">WaveNet</th>
<th style="text-align: center">DSP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/recording_2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/ddpm_2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/warpnet_2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/wavenet_2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/dsp_2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<p><em>Sample 3.</em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Recording</th>
<th style="text-align: center">BinauralGrad</th>
<th style="text-align: center">WarpNet</th>
<th style="text-align: center">WaveNet</th>
<th style="text-align: center">DSP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/recording_3.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/ddpm_3.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/warpnet_3.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/wavenet_3.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/dsp_3.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<p><em>Sample 4.</em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Recording</th>
<th style="text-align: center">BinauralGrad</th>
<th style="text-align: center">WarpNet</th>
<th style="text-align: center">WaveNet</th>
<th style="text-align: center">DSP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/recording_4.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/ddpm_4.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/warpnet_4.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/wavenet_4.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/dsp_4.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<p><em>Sample 5.</em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Recording</th>
<th style="text-align: center">BinauralGrad</th>
<th style="text-align: center">WarpNet</th>
<th style="text-align: center">WaveNet</th>
<th style="text-align: center">DSP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/recording_5.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/ddpm_5.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/warpnet_5.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/wavenet_5.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/binauralgrad/dsp_5.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>
<h2 id="inference-speedup">Case Study</h2>
<p> We randomly select three cases from the test set to intuitively compare the proposed BinauralGrad with other baselines. For each sample we plot 2 sub-figures, each with N=1000 sampling points in a sampling rate of 48kHz, and the time length of each sample is around 0.021s.</p> 

<p> One sub-figure (e.g., Figure 1(a), 2(a), 3(a)) shows the waveform of the mono audio, the ground-truth (GT) binaural audio and the generated binaural audio with amplitude information, in which we can visually check the time delay with the red dashed lines, and we can also compare the difference between different models. Another sub-figure (e.g., Figure 1(b), 2(b), 3(b)) shows the prediction error between generated audio and GT audio. The blue lines show the GT results, while the red lines represent the prediction error at each sampling point. The prediction error of each model is shown in the same range [-0.2, 0.2]. </p>

<img src="../images/binauralgrad/figure1.png" width="85%" class="center"/>

<p> For these three cases, as shown in Figure 1, Figure 2 and Figure 3, we can find that BinauralGrad precisely predicts the GT waveform in both left ear audio and right ear audio. In most situations, the prediction error is close to Gaussian noise. As a comparison, WarpNet sometimes adds small artifacts on the waveform. And the prediction is not stable for binaural audios. As it can be seen in Figure 1, the prediction error of left ear audio is small, but the extra artifacts are especially apparent in the right ear audio when N in [0, 100], [350, 450], [670, 770]. Moreover, in both Figure 2 and Figure 3, we can see obvious prediction error which even shows similarity with GT waveform in both left and right ear. For WaveNet, it may fail to accurately predict the GT waveform, which can be seen from Figure 1 and Figure 3. For DSP, the estimation results are not as good as other models either in the time delay or the amplitude prediction. </p>

<img src="../images/binauralgrad/figure2.png" width="85%" class="center"/>

<img src="../images/binauralgrad/figure3.png" width="85%" class="center"/>

<p> To sum up, in our test experiments, we find that our proposed BinauralGrad is advantageous in binaural audio waveform reconstruction. Compared to other models, the prediction error of our model is smaller. Especially, our results are more stable. Sometimes, other models can achieve small prediction error in one ear, but they fail to accurately model the waveform of the other ear. BinauralGrad can simultaneously achieve accurate predictions in both left ear and right ear. </p>


<p> For other models, WarpNet sometimes adds extra artifacts on waveforms, which may be caused by their multiple methods to strengthen the phase estimation. And its prediction error is large in some time periods. WaveNet may fail to predict fine-grained details of GT waveforms because it only uses position as (a weak) condition information but not uses warping (proposed in WarpNet). DSP estimation results, where a generic (not-personalized) HRTF (head-related transfer functions) and RIR (room impulse response) is used since the dataset does not contains HRTF and RIR, are not as good as other models and its prediction error is usually much larger than other results. </p>

<h2 id="our-related-works">Our Related Works</h2>
<p>
<a href="https://speechresearch.github.io/">Some speech research conducted at Microsoft Research Asia</a><br>	
<a href="/naturalspeech/">NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality</a><br>
<a href="/fastspeech/">FastSpeech: Fast, Robust and Controllable Text to Speech</a><br>
<a href="/fastspeech2/">FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech</a><br>
<a href="/adaspeech/">AdaSpeech: Adaptive Text to Speech for Custom Voice</a><br>
<a href="/adaspeech2/">AdaSpeech 2: Adaptive Text to Speech with Untranscribed Data</a><br>
<a href="/adaspeech3/">AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style</a><br>
<a href="/adaspeech4/">AdaSpeech 4: Adaptive Text to Speech in Zero-Shot Scenarios</a><br>
<a href="/priorgrad/">PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior</a><br>
</p>

			</section>
		</article>
	</main>


	

</div>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-139981676-1', 'auto');
	ga('send', 'pageview');
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>

 <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

 <script type="text/javascript" async
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
 </script>




</body>
</html>

